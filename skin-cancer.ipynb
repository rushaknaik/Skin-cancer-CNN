{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport pandas as pd\nimport numpy as np\nimport shutil\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\n# Define dataset paths\ndataset_path = \"/kaggle/input/skin-cancer-mnist-ham10000\"  # Replace with the exact dataset folder name\nimages_dir = f\"{dataset_path}/HAM10000_images_part_1\"\nmeta_data_path = f\"{dataset_path}/HAM10000_metadata.csv\"\n\n# Check if paths exist\nprint(\"Images Directory:\", os.listdir(images_dir)[:5])  # Print the first few image names\nprint(\"Metadata File Exists:\", os.path.exists(meta_data_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T06:10:20.094278Z","iopub.execute_input":"2024-12-02T06:10:20.094843Z","iopub.status.idle":"2024-12-02T06:10:37.291368Z","shell.execute_reply.started":"2024-12-02T06:10:20.094785Z","shell.execute_reply":"2024-12-02T06:10:37.290223Z"}},"outputs":[{"name":"stdout","text":"Images Directory: ['ISIC_0028933.jpg', 'ISIC_0028394.jpg', 'ISIC_0027799.jpg', 'ISIC_0028100.jpg', 'ISIC_0027960.jpg']\nMetadata File Exists: True\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Load metadata\nmeta_data = pd.read_csv(meta_data_path)\n\n# Display the first few rows\nprint(meta_data.head())\n\n# Check label distribution\nprint(meta_data['dx'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T06:10:37.293275Z","iopub.execute_input":"2024-12-02T06:10:37.293952Z","iopub.status.idle":"2024-12-02T06:10:37.349948Z","shell.execute_reply.started":"2024-12-02T06:10:37.293913Z","shell.execute_reply":"2024-12-02T06:10:37.348734Z"}},"outputs":[{"name":"stdout","text":"     lesion_id      image_id   dx dx_type   age   sex localization\n0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\ndx\nnv       6705\nmel      1113\nbkl      1099\nbcc       514\nakiec     327\nvasc      142\ndf        115\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Extract image file names and labels\nimage_ids = meta_data['image_id'].values\nlabels = meta_data['dx'].values\n\n# Create train-test split\ntrain_ids, val_ids, train_labels, val_labels = train_test_split(\n    image_ids, labels, test_size=0.2, stratify=labels, random_state=42\n)\n\nprint(f\"Training Samples: {len(train_ids)}\")\nprint(f\"Validation Samples: {len(val_ids)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T06:10:37.351270Z","iopub.execute_input":"2024-12-02T06:10:37.351649Z","iopub.status.idle":"2024-12-02T06:10:37.372911Z","shell.execute_reply.started":"2024-12-02T06:10:37.351612Z","shell.execute_reply":"2024-12-02T06:10:37.371649Z"}},"outputs":[{"name":"stdout","text":"Training Samples: 8012\nValidation Samples: 2003\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Create directories for training and validation\ntrain_dir = \"/kaggle/working/train\"\nval_dir = \"/kaggle/working/validation\"\n\n# Helper function to organize images\ndef organize_images(image_ids, labels, src_dir, dest_dir):\n    for img_id, label in zip(image_ids, labels):\n        label_dir = os.path.join(dest_dir, label)\n        os.makedirs(label_dir, exist_ok=True)\n        \n        src_path = os.path.join(src_dir, f\"{img_id}.jpg\")\n        dest_path = os.path.join(label_dir, f\"{img_id}.jpg\")\n        \n        if os.path.exists(src_path):\n            shutil.copy(src_path, dest_path)\n\n# Organize images\norganize_images(train_ids, train_labels, images_dir, train_dir)\norganize_images(val_ids, val_labels, images_dir, val_dir)\n\nprint(\"Train and Validation directories created!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T06:10:37.374326Z","iopub.execute_input":"2024-12-02T06:10:37.374702Z","iopub.status.idle":"2024-12-02T06:11:31.957534Z","shell.execute_reply.started":"2024-12-02T06:10:37.374668Z","shell.execute_reply":"2024-12-02T06:11:31.956137Z"}},"outputs":[{"name":"stdout","text":"Train and Validation directories created!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport shutil\nimport cv2  # Ensure OpenCV is imported\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Augmentation setup\naugmentation_generator = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Augment minority classes\ndef augment_all_minority_classes(train_dir, target_count):\n    \"\"\"\n    Augments all classes in the training directory to match the target_count.\n    \n    Args:\n    - train_dir: Path to the training directory.\n    - target_count: Desired number of images for each class.\n    \"\"\"\n    classes = os.listdir(train_dir)\n    \n    for class_name in classes:\n        target_dir = os.path.join(train_dir, class_name)\n        current_images = os.listdir(target_dir)\n        current_count = len(current_images)\n        \n        print(f\"Processing class '{class_name}' with {current_count} images...\")\n        \n        # Augment only if the current count is less than the target count\n        if current_count < target_count:\n            while current_count < target_count:\n                for img_name in current_images:\n                    img_path = os.path.join(target_dir, img_name)\n                    img = cv2.imread(img_path)  # Read image\n                    if img is None:\n                        print(f\"Failed to read {img_path}. Skipping...\")\n                        continue\n                    img = cv2.resize(img, (128, 128))  # Resize to 128x128\n                    img = np.expand_dims(img, axis=0)  # Add batch dimension\n\n                    # Perform augmentation and save images\n                    for batch in augmentation_generator.flow(\n                        img, batch_size=1, save_to_dir=target_dir, save_prefix='aug', save_format='jpg'\n                    ):\n                        current_count += 1\n                        if current_count >= target_count:\n                            break\n            print(f\"Class '{class_name}' augmented to {current_count} images.\")\n        else:\n            print(f\"Class '{class_name}' already has sufficient images.\")\n\n# Example: Augment all classes to 6705 images\naugment_all_minority_classes(train_dir, target_count=6705)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T06:11:31.960264Z","iopub.execute_input":"2024-12-02T06:11:31.960671Z"}},"outputs":[{"name":"stdout","text":"Processing class 'bkl' with 452 images...\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Get class distribution and labels\nfrom sklearn.utils.class_weight import compute_class_weight\n\nclass_labels = os.listdir(train_dir)\nlabel_to_index = {label: idx for idx, label in enumerate(class_labels)}\n\n# Prepare train_labels from augmented dataset\ntrain_labels = []\nfor label in class_labels:\n    label_dir = os.path.join(train_dir, label)\n    train_labels.extend([label] * len(os.listdir(label_dir)))\n\n# Compute class weights\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.array(class_labels),\n    y=train_labels\n)\n\n# Map weights to class indices\nclass_weights_dict = {label_to_index[label]: weight for label, weight in zip(class_labels, class_weights)}\nprint(\"Class Weights:\", class_weights_dict)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\n# Define CNN Model\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n    MaxPooling2D((2, 2)),\n    \n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    \n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    \n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(len(class_labels), activation='softmax')  # Output layer\n])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data generators\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nval_datagen = ImageDataGenerator(rescale=1./255)\n\n# Training generator\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(128, 128),\n    batch_size=32,\n    class_mode='categorical'\n)\n\n# Validation generator\nval_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size=(128, 128),\n    batch_size=32,\n    class_mode='categorical'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=21,\n    class_weight=class_weights_dict  # Apply class weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Initialize the ImageDataGenerator for the test dataset\ntest_datagen = ImageDataGenerator(rescale=1.0 / 255)  # Normalize pixel values to [0, 1]\n\n# Define the directory where the test dataset is stored\ntest_dir = val_dir  # Replace with your test dataset directory\n\n# Create the test data generator\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(128, 128),  # Image size should match the input size of your model\n    batch_size=32,  # Number of images to process in a batch\n    class_mode='categorical',  # The labels are one-hot encoded\n    shuffle=False  # Ensure images are not shuffled to maintain correct order for evaluation\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Step 1: Evaluate the model on the test dataset\ntest_loss, test_accuracy = model.evaluate(test_generator)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n\n# Step 2: Predict on the test data\ny_true = test_generator.classes  # True labels from the test set\ny_pred = model.predict(test_generator)  # Model predictions\n\n# Convert predictions from probabilities to class indices\ny_pred_classes = np.argmax(y_pred, axis=1)\n\n# Step 3: Generate the confusion matrix\nconf_matrix = confusion_matrix(y_true, y_pred_classes)\n\n# Visualize the confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(),\n            yticklabels=test_generator.class_indices.keys())\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Step 4: Generate a classification report\nclass_report = classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys())\nprint(\"Classification Report:\")\nprint(class_report)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Assume 'history' is the object returned from model.fit or model.fit_generator\n# Example: history = model.fit(train_generator, validation_data=val_generator, epochs=20)\n\n# Extract metrics\naccuracy = history.history['accuracy']  # Training accuracy\nval_accuracy = history.history['val_accuracy']  # Validation accuracy\nloss = history.history['loss']  # Training loss\nval_loss = history.history['val_loss']  # Validation loss\nepochs = range(1, len(accuracy) + 1)  # Epochs\n\n# Plot Training and Validation Accuracy\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epochs, accuracy, label='Training Accuracy', marker='o')\nplt.plot(epochs, val_accuracy, label='Validation Accuracy', marker='o')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plot Training and Validation Loss\nplt.subplot(1, 2, 2)\nplt.plot(epochs, loss, label='Training Loss', marker='o')\nplt.plot(epochs, val_loss, label='Validation Loss', marker='o')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history2 = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=51,\n    class_weight=class_weights_dict  # Apply class weights\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Step 1: Evaluate the model on the test dataset\ntest_loss, test_accuracy = model.evaluate(test_generator)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n\n# Step 2: Predict on the test data\ny_true = test_generator.classes  # True labels from the test set\ny_pred = model.predict(test_generator)  # Model predictions\n\n# Convert predictions from probabilities to class indices\ny_pred_classes = np.argmax(y_pred, axis=1)\n\n# Step 3: Generate the confusion matrix\nconf_matrix = confusion_matrix(y_true, y_pred_classes)\n\n# Visualize the confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(),\n            yticklabels=test_generator.class_indices.keys())\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Step 4: Generate a classification report\nclass_report = classification_report(y_true, y_pred_classes, target_names=test_generator.class_indices.keys())\nprint(\"Classification Report:\")\nprint(class_report)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Assume 'history' is the object returned from model.fit or model.fit_generator\n# Example: history = model.fit(train_generator, validation_data=val_generator, epochs=20)\n\n# Extract metrics\naccuracy = history2.history['accuracy']  # Training accuracy\nval_accuracy = history2.history['val_accuracy']  # Validation accuracy\nloss = history2.history['loss']  # Training loss\nval_loss = history2.history['val_loss']  # Validation loss\nepochs = range(1, len(accuracy) + 1)  # Epochs\n\n# Plot Training and Validation Accuracy\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epochs, accuracy, label='Training Accuracy', marker='o')\nplt.plot(epochs, val_accuracy, label='Validation Accuracy', marker='o')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plot Training and Validation Loss\nplt.subplot(1, 2, 2)\nplt.plot(epochs, loss, label='Training Loss', marker='o')\nplt.plot(epochs, val_loss, label='Validation Loss', marker='o')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the path to save the model in the Kaggle output directory\nmodel_save_path = '/kaggle/working/saved_model.h5'\n\n# Save the model\nmodel.save(model_save_path)\n\nprint(f\"Model saved to: {model_save_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}